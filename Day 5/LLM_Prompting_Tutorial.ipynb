{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Outline of the Session\n",
        "\n",
        "1. Prompting setup and basics. How to call an LLM via API?\n",
        "2. Understanding few-shot prompting - An NLI Illustration\n",
        "3. LLMs for Reasoning - Task Definitions and Requirements\n",
        "4. Advanced Prompting Techniques - CoT, Self-consistency and PAL\n",
        "\n"
      ],
      "metadata": {
        "id": "8JNp3dpdzKpf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prerequisite\n",
        "\n",
        "For this tutorial, you will use Groq and together.ai for running LLM inference.\n",
        "\n",
        "### Setting Up Groq\n",
        "1. Go to https://groq.com/.\n",
        "2. Sign In using your favourite Email Id.\n",
        "3. Click on GroqCloud.\n",
        "4. Create an API Key with name \"Tutorial\".\n",
        "5. Copy the API Key and same it in GROQ_API_KEY variable.\n",
        "6. Install groq package with pip.\n",
        "7. Test it on a sample input.\n",
        "\n",
        "Additional documentation can be found at https://console.groq.com/docs/quickstart."
      ],
      "metadata": {
        "id": "-kUHOtUzZSdu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pandas\n",
        "!pip install scikit-learn\n",
        "!pip install tqdm\n",
        "!pip install datasets"
      ],
      "metadata": {
        "id": "D0P-hgmThD9R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "GROQ_API_KEY = 'ADD YOUR API KEY HERE'\n",
        "!pip install groq"
      ],
      "metadata": {
        "id": "hYjnXwuOa-Q0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from groq import Groq\n",
        "client = Groq(api_key=GROQ_API_KEY)\n",
        "\n",
        "def run_groq_model(messages, model, temperature=0.7, top_p=1, max_tokens=16):\n",
        "    chat_completion = client.chat.completions.create(\n",
        "        messages=messages, temperature=temperature, top_p=top_p,\n",
        "        model=model, n=1, max_tokens=max_tokens\n",
        "    )\n",
        "    return chat_completion.choices[0].message.content"
      ],
      "metadata": {
        "id": "JVRLIJo8b2MU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ret = run_groq_model([{\"role\": \"user\", \"content\": \"Introduce yourself.\"}], \"llama3-8b-8192\", max_tokens=100)\n",
        "print(ret)"
      ],
      "metadata": {
        "id": "z2ALNhD8b2Vo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ret = run_groq_model([{\"role\": \"user\", \"content\": \"Introduce yourself.\"}], \"llama3-8b-8192\", max_tokens=100)\n",
        "print(ret)"
      ],
      "metadata": {
        "id": "MPAgz1lob2Yq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ret = run_groq_model([{\"role\": \"user\", \"content\": \"Introduce yourself.\"}], \"llama3-8b-8192\", max_tokens=100)\n",
        "print(ret)"
      ],
      "metadata": {
        "id": "AoCuQyncb2bj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Try another model\n",
        "ret = run_groq_model([{\"role\": \"user\", \"content\": \"Introduce yourself.\"}], \"mixtral-8x7b-32768\", max_tokens=100)\n",
        "print(ret)"
      ],
      "metadata": {
        "id": "a69ABTbMb2eq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Play with generation parameters"
      ],
      "metadata": {
        "id": "930cLdQJiKsf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Deterministic response\n",
        "ret = run_groq_model([{\"role\": \"user\", \"content\": \"Describe the planet Jupiter in few words.\"}], \"mixtral-8x7b-32768\", max_tokens=100, temperature=0.0)\n",
        "print(ret)"
      ],
      "metadata": {
        "id": "asj8WT_qiHQJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ret = run_groq_model([{\"role\": \"user\", \"content\": \"Describe the planet Jupiter in few words.\"}], \"mixtral-8x7b-32768\", max_tokens=100, temperature=0.0)\n",
        "print(ret)"
      ],
      "metadata": {
        "id": "N88fPIYIip3g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ret = run_groq_model([{\"role\": \"user\", \"content\": \"Describe the planet Jupiter in few words.\"}], \"mixtral-8x7b-32768\", max_tokens=100, temperature=0.9)\n",
        "print(ret)"
      ],
      "metadata": {
        "id": "qDBkkIY6ixZn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Understanding few-shot prompting - An NLI Illustration\n",
        "\n",
        "\n",
        "As beginners, we start with an NLP task.\n",
        "\n",
        "Natural language inference (NLI) is basically a reading comprehension task for computers. Imagine you are reading a passage (premise) and then asked a question (hypothesis). NLI  focuses on whether the question can be answered based on the information in the passage alone.\n",
        "\n",
        "Here's a breakdown:\n",
        "\n",
        "* There are two main parts: a **premise** (the background information) and a **hypothesis** (the question).\n",
        "* The task is to determine the relationship between the two:\n",
        "    * Does the answer to the question (hypothesis) necessarily follow from the information given (premise)? (**entailment**)\n",
        "    * Does the answer to the question contradict the information given? (**contradiction**)\n",
        "    * Is there not enough information in the passage to say for sure? (**neutral**)\n",
        "\n",
        "NLI helps computers better understand the nuances of language and logic, which is useful for tasks like question answering and fact checking."
      ],
      "metadata": {
        "id": "6axtlggCycH9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset = [\n",
        "    # Entailment\n",
        "    {\"premise\": \"A soccer game with multiple males playing.\", \"hypothesis\": \"Some men are playing a sport.\", \"label\": \"entailment\"},\n",
        "    {\"premise\": \"A woman is reading a book.\", \"hypothesis\": \"A female is holding a book.\", \"label\": \"entailment\"},\n",
        "    {\"premise\": \"The cat is sleeping on the couch.\", \"hypothesis\": \"A cat is resting.\", \"label\": \"entailment\"},\n",
        "    {\"premise\": \"A man is eating a sandwich.\", \"hypothesis\": \"A person is having a meal.\", \"label\": \"entailment\"},\n",
        "    {\"premise\": \"A group of people are walking in the park.\", \"hypothesis\": \"People are outdoors.\", \"label\": \"entailment\"},\n",
        "    {\"premise\": \"A child is drawing with crayons.\", \"hypothesis\": \"A kid is making art.\", \"label\": \"entailment\"},\n",
        "    {\"premise\": \"The chef is cooking in the kitchen.\", \"hypothesis\": \"Someone is preparing food.\", \"label\": \"entailment\"},\n",
        "    {\"premise\": \"A dog is barking loudly.\", \"hypothesis\": \"A dog is making noise.\", \"label\": \"entailment\"},\n",
        "    {\"premise\": \"Two kids are playing with a ball.\", \"hypothesis\": \"Children are engaged in a game.\", \"label\": \"entailment\"},\n",
        "    {\"premise\": \"The sun is shining brightly.\", \"hypothesis\": \"It is sunny outside.\", \"label\": \"entailment\"},\n",
        "    {\"premise\": \"A teacher is writing on the board.\", \"hypothesis\": \"An instructor is using chalk.\", \"label\": \"entailment\"},\n",
        "    {\"premise\": \"The musician is playing the guitar.\", \"hypothesis\": \"Someone is performing music.\", \"label\": \"entailment\"},\n",
        "    {\"premise\": \"The flowers are blooming in the garden.\", \"hypothesis\": \"Plants are growing in the yard.\", \"label\": \"entailment\"},\n",
        "    {\"premise\": \"A person is jogging on the beach.\", \"hypothesis\": \"Someone is running near the water.\", \"label\": \"entailment\"},\n",
        "    {\"premise\": \"A car is parked on the street.\", \"hypothesis\": \"A vehicle is on the road.\", \"label\": \"entailment\"},\n",
        "    {\"premise\": \"A baby is crawling on the floor.\", \"hypothesis\": \"An infant is moving on the ground.\", \"label\": \"entailment\"},\n",
        "    {\"premise\": \"A boy is riding a bicycle.\", \"hypothesis\": \"A child is on a bike.\", \"label\": \"entailment\"},\n",
        "    {\"premise\": \"The birds are flying in the sky.\", \"hypothesis\": \"Some animals are in the air.\", \"label\": \"entailment\"},\n",
        "    {\"premise\": \"A couple is dancing at the wedding.\", \"hypothesis\": \"Two people are celebrating.\", \"label\": \"entailment\"},\n",
        "    {\"premise\": \"A student is studying for an exam.\", \"hypothesis\": \"Someone is preparing for a test.\", \"label\": \"entailment\"},\n",
        "\n",
        "    # Neutral\n",
        "    {\"premise\": \"A man is playing a guitar.\", \"hypothesis\": \"The man is performing at a concert.\", \"label\": \"neutral\"},\n",
        "    {\"premise\": \"A woman is jogging in the morning.\", \"hypothesis\": \"She is training for a marathon.\", \"label\": \"neutral\"},\n",
        "    {\"premise\": \"A dog is playing in the yard.\", \"hypothesis\": \"The dog is digging a hole.\", \"label\": \"neutral\"},\n",
        "    {\"premise\": \"A group of kids are playing football.\", \"hypothesis\": \"The children are at school.\", \"label\": \"neutral\"},\n",
        "    {\"premise\": \"A man is fixing his car.\", \"hypothesis\": \"The car had a flat tire.\", \"label\": \"neutral\"},\n",
        "    {\"premise\": \"A chef is preparing a meal.\", \"hypothesis\": \"The chef is making an Italian dish.\", \"label\": \"neutral\"},\n",
        "    {\"premise\": \"A person is reading a newspaper.\", \"hypothesis\": \"The person is at a coffee shop.\", \"label\": \"neutral\"},\n",
        "    {\"premise\": \"A child is drawing with crayons.\", \"hypothesis\": \"The child is creating a masterpiece.\", \"label\": \"neutral\"},\n",
        "    {\"premise\": \"A family is having a picnic.\", \"hypothesis\": \"The family is celebrating a birthday.\", \"label\": \"neutral\"},\n",
        "    {\"premise\": \"A woman is planting flowers.\", \"hypothesis\": \"The woman is a professional gardener.\", \"label\": \"neutral\"},\n",
        "    {\"premise\": \"A man is swimming in the pool.\", \"hypothesis\": \"The man is training for a competition.\", \"label\": \"neutral\"},\n",
        "    {\"premise\": \"A boy is riding a skateboard.\", \"hypothesis\": \"The boy is practicing for a contest.\", \"label\": \"neutral\"},\n",
        "    {\"premise\": \"A couple is walking their dog.\", \"hypothesis\": \"The couple adopted the dog recently.\", \"label\": \"neutral\"},\n",
        "    {\"premise\": \"A student is taking notes in class.\", \"hypothesis\": \"The student is preparing for a quiz.\", \"label\": \"neutral\"},\n",
        "    {\"premise\": \"A man is drinking coffee.\", \"hypothesis\": \"The man is at a business meeting.\", \"label\": \"neutral\"},\n",
        "    {\"premise\": \"A woman is baking a cake.\", \"hypothesis\": \"The cake is for a wedding.\", \"label\": \"neutral\"},\n",
        "    {\"premise\": \"A child is playing the piano.\", \"hypothesis\": \"The child is a prodigy.\", \"label\": \"neutral\"},\n",
        "    {\"premise\": \"A girl is reading a book.\", \"hypothesis\": \"The book is about science.\", \"label\": \"neutral\"},\n",
        "    {\"premise\": \"A man is mowing the lawn.\", \"hypothesis\": \"The man is a gardener.\", \"label\": \"neutral\"},\n",
        "    {\"premise\": \"A teacher is grading papers.\", \"hypothesis\": \"The teacher is teaching high school.\", \"label\": \"neutral\"},\n",
        "\n",
        "    # Contradiction\n",
        "    {\"premise\": \"A cat is sitting on the windowsill.\", \"hypothesis\": \"The cat is outside.\", \"label\": \"contradiction\"},\n",
        "    {\"premise\": \"A woman is shopping for groceries.\", \"hypothesis\": \"The woman is at home.\", \"label\": \"contradiction\"},\n",
        "    {\"premise\": \"A man is playing basketball.\", \"hypothesis\": \"The man is sitting on the bench.\", \"label\": \"contradiction\"},\n",
        "    {\"premise\": \"A child is watching television.\", \"hypothesis\": \"The child is playing outside.\", \"label\": \"contradiction\"},\n",
        "    {\"premise\": \"A dog is barking at a stranger.\", \"hypothesis\": \"The dog is sleeping.\", \"label\": \"contradiction\"},\n",
        "    {\"premise\": \"A group of friends are having dinner.\", \"hypothesis\": \"The friends are at the park.\", \"label\": \"contradiction\"},\n",
        "    {\"premise\": \"A woman is writing a letter.\", \"hypothesis\": \"The woman is typing on a computer.\", \"label\": \"contradiction\"},\n",
        "    {\"premise\": \"A man is jogging in the park.\", \"hypothesis\": \"The man is sitting on a bench.\", \"label\": \"contradiction\"},\n",
        "    {\"premise\": \"A chef is cooking in the kitchen.\", \"hypothesis\": \"The chef is cleaning the kitchen.\", \"label\": \"contradiction\"},\n",
        "    {\"premise\": \"A student is studying in the library.\", \"hypothesis\": \"The student is at a party.\", \"label\": \"contradiction\"},\n",
        "    {\"premise\": \"A person is driving a car.\", \"hypothesis\": \"The person is riding a bicycle.\", \"label\": \"contradiction\"},\n",
        "    {\"premise\": \"A woman is swimming in the ocean.\", \"hypothesis\": \"The woman is sunbathing.\", \"label\": \"contradiction\"},\n",
        "    {\"premise\": \"A man is reading a book.\", \"hypothesis\": \"The man is playing a video game.\", \"label\": \"contradiction\"},\n",
        "    {\"premise\": \"A child is building a sandcastle.\", \"hypothesis\": \"The child is flying a kite.\", \"label\": \"contradiction\"},\n",
        "    {\"premise\": \"A group of people are watching a movie.\", \"hypothesis\": \"The people are playing a game.\", \"label\": \"contradiction\"},\n",
        "    {\"premise\": \"A man is fishing at the lake.\", \"hypothesis\": \"The man is hiking in the mountains.\", \"label\": \"contradiction\"},\n",
        "    {\"premise\": \"A girl is painting a picture.\", \"hypothesis\": \"The girl is reading a book.\", \"label\": \"contradiction\"},\n",
        "    {\"premise\": \"A woman is listening to music.\", \"hypothesis\": \"The woman is talking on the phone.\", \"label\": \"contradiction\"},\n",
        "    {\"premise\": \"A child is playing with toys.\", \"hypothesis\": \"The child is asleep.\", \"label\": \"contradiction\"},\n",
        "    {\"premise\": \"A man is walking his dog.\", \"hypothesis\": \"The man is riding a bicycle.\", \"label\": \"contradiction\"}\n",
        "]"
      ],
      "metadata": {
        "id": "U8l2Xvx7yXTJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Let's design a prompt to solve the NLI task."
      ],
      "metadata": {
        "id": "uQTSebui1yx8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def nli_prompt(premise, hypothesis):\n",
        "    \"\"\"\n",
        "    Design a prompt to solve the NLI task. A prompt typically contains\n",
        "    1. A system message\n",
        "    2. Alternate User and System messages.\n",
        "\n",
        "    These are not concrete requirements and you can design your own prompt.\n",
        "    \"\"\"\n",
        "\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": \"ADD NLI INSTRUCTIONS HERE\"},\n",
        "        {\"role\": \"user\", \"content\": \"ADD NLU INPUTS\"},\n",
        "    ] # model will generate the output\n",
        "\n",
        "    return messages"
      ],
      "metadata": {
        "id": "UFAUGqgYyZLS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = []\n",
        "\n",
        "for entry in test_dataset:\n",
        "    messages = nli_prompt(entry['premise'], entry['hypothesis'])\n",
        "    ret = run_groq_model(messages, \"llama3-8b-8192\", max_tokens=16, temperature=0.0)\n",
        "    results.append(ret)"
      ],
      "metadata": {
        "id": "2Ai3PyluyZPZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results[:10]"
      ],
      "metadata": {
        "id": "WGAg3QwQyZTK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### We are not able to parse the output of the model. How can we specify the output format?"
      ],
      "metadata": {
        "id": "cllITednrPzc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "exemplars = [\n",
        "    {\"premise\": \"A boy is jumping into the pool.\", \"hypothesis\": \"A child is entering the water.\", \"label\": \"entailment\"},\n",
        "    {\"premise\": \"The artist is painting a landscape.\", \"hypothesis\": \"Someone is creating art.\", \"label\": \"entailment\"},\n",
        "    {\"premise\": \"A man is running a marathon.\", \"hypothesis\": \"The man will win the race.\", \"label\": \"neutral\"},\n",
        "    {\"premise\": \"A girl is reading under a tree.\", \"hypothesis\": \"The girl is studying for exams.\", \"label\": \"neutral\"},\n",
        "    {\"premise\": \"A woman is cooking dinner.\", \"hypothesis\": \"The woman is dining out.\", \"label\": \"contradiction\"},\n",
        "    {\"premise\": \"A dog is playing with a ball.\", \"hypothesis\": \"The dog is sleeping.\", \"label\": \"contradiction\"}\n",
        "]"
      ],
      "metadata": {
        "id": "-xQqj4cIyZWn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def nli_prompt_with_exemplars(premise, hypothesis, exemplars):\n",
        "    \"\"\"\n",
        "    Design a prompt to solve the NLI task. A prompt typically contains\n",
        "    1. A system message\n",
        "    2. Alternate User and System messages. Use exemplars here.\n",
        "    \"\"\"\n",
        "\n",
        "    messages = [{\"role\": \"system\", \"content\": \"ADD NLI INSTRUCTIONS HERE\"}]\n",
        "    for ee in exemplars:\n",
        "        messages.append({\"role\": \"user\", \"content\": \"ADD NLU INPUT HERE\"})\n",
        "        messages.append({\"role\": \"assistant\", \"content\": \"ADD NLI OUTPUT HERE\"})\n",
        "    messages.append({\"role\": \"user\", \"content\": f\"ADD NLI INPUT HERE\"})\n",
        "\n",
        "    return messages"
      ],
      "metadata": {
        "id": "VaXqNKJKyZZ-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = []\n",
        "\n",
        "for entry in tqdm(test_dataset):\n",
        "    messages = nli_prompt_with_exemplars(entry['premise'], entry['hypothesis'], exemplars)\n",
        "    ret = run_groq_model(messages, \"llama3-8b-8192\", max_tokens=16, temperature=0.0)\n",
        "    results.append(ret)"
      ],
      "metadata": {
        "id": "e1FQTMphyZc_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results[:10]"
      ],
      "metadata": {
        "id": "HCHfsY5_yZgO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Now, parse the ouput to obtain final predictions."
      ],
      "metadata": {
        "id": "x-n-UCvgreYX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def post(text):\n",
        "    return text.replace('Answer: ', '').strip()"
      ],
      "metadata": {
        "id": "G0K2codWH8qK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds = [post(x) for x in results]\n",
        "golds = [x['label'] for x in test_dataset]\n",
        "print(Counter(preds))\n",
        "print('Accuracy', accuracy_score(golds, preds))"
      ],
      "metadata": {
        "id": "E6hFeaxUIEEI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = []\n",
        "\n",
        "for entry in tqdm(test_dataset):\n",
        "    messages = nli_prompt_with_exemplars(entry['premise'], entry['hypothesis'], exemplars)\n",
        "    ret = run_groq_model(messages, \"mixtral-8x7b-32768\", max_tokens=16, temperature=0.0)\n",
        "    results.append(ret)\n"
      ],
      "metadata": {
        "id": "dKCiU5oxIJQj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results[:10]"
      ],
      "metadata": {
        "id": "azjh6iUqJFeF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def post(text):\n",
        "    return text.split('\\n')[0].replace('Answer: ', '').strip()\n",
        "\n",
        "preds = [post(x) for x in results]\n",
        "golds = [x['label'] for x in test_dataset]\n",
        "print(Counter(preds))\n",
        "print('Accuracy', accuracy_score(golds, preds))"
      ],
      "metadata": {
        "id": "gvLrTY3rJLxB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. LLMs for Reasoning - Task Definitions and Requirements\n",
        "\n",
        "### Solving Simple Math Problems with LLMs\n",
        "\n",
        "We will play with GSM8K dataset consisting of school level math word problems.\n",
        "Our objective is to use Llama and Mixtral models to solve these math word problems.\n",
        "\n",
        "GSM8K, short for Grade School Math 8K, is a collection of math problems designed to challenge computers. Imagine a test for AI models, but instead of spelling bees, it's solving word problems!\n",
        "\n",
        "Here's an example problem:\n",
        "\n",
        "    Sarah has 10 cookies. She gives 3 to her friend. How many cookies does Sarah have left?\n",
        "\n",
        "This problem requires two steps:\n",
        "\n",
        "    Subtract the number of cookies given away (3) from the starting number (10).\n",
        "    Find the answer (7 cookies).\n",
        "\n",
        "To solve GSM8K problems, LLMs must identify different variables and their assignments (number_of_cookies=10), reason out the involved operations (number_of_cookies - 3) and output the final answer.\n",
        "\n",
        "## Download the dataset using Huggingface"
      ],
      "metadata": {
        "id": "I10lWP2wZF3H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "dataset = load_dataset(\"openai/gsm8k\", \"main\")"
      ],
      "metadata": {
        "id": "19WW7aguq5-f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_final_answer(entry):\n",
        "    entry['numerical_answer'] = entry['answer'].split('\\n')[-1].split(' ', 1)[-1].strip()\n",
        "\n",
        "    return entry"
      ],
      "metadata": {
        "id": "dA3l3-OXkcu3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[\"train\"][0]"
      ],
      "metadata": {
        "id": "12AE6Dj8sDUT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset['train'] = dataset['train'].map(get_final_answer)\n",
        "dataset['test'] = dataset['test'].map(get_final_answer)"
      ],
      "metadata": {
        "id": "4pwWk-vqk1m2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(dataset['test'][0])"
      ],
      "metadata": {
        "id": "AXbDbJiclIgM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset = dataset['test'].train_test_split(test_size=50, seed=42)['test']"
      ],
      "metadata": {
        "id": "h7wptIzhroJB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset[0]"
      ],
      "metadata": {
        "id": "d4mdjgjxmvSd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_accuracy(golds, preds):\n",
        "    cnt = 0\n",
        "    for gg, pp in zip(golds, preds):\n",
        "        gg = float(gg.replace(',', ''))\n",
        "        try:\n",
        "            pp = float(pp.replace(',', ''))\n",
        "        except:\n",
        "            pp = None\n",
        "\n",
        "        if gg == pp:\n",
        "            cnt += 1\n",
        "    return cnt / len(golds)"
      ],
      "metadata": {
        "id": "7SKCwWXhoBmZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Few-shot Exemplars"
      ],
      "metadata": {
        "id": "eFYVKaRqjJyC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "from collections import Counter\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "metadata": {
        "id": "5G5kvTwjoTrX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "exemplars = [dataset['train'][ii] for ii in range(5)]"
      ],
      "metadata": {
        "id": "gwsxyg8InLBb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def few_shot_prompt(test_entry, exemplars):\n",
        "    messages = [{\"role\": \"system\", \"content\": \"MATH PROBLEM INSTRUCTIONS\"}]\n",
        "    for entry in exemplars:\n",
        "        messages.append({\"role\": \"user\", \"content\": \"QUESTION HERE\"})\n",
        "        messages.append({\"role\": \"assistant\", \"content\": \"ANSWER HERE\"})\n",
        "    messages.append({\"role\": \"user\", \"content\": \"QUESTION HERE\"})\n",
        "\n",
        "    return messages"
      ],
      "metadata": {
        "id": "U3eBClUindVW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = []\n",
        "for entry in tqdm(test_dataset):\n",
        "    messages = few_shot_prompt(entry, exemplars)\n",
        "    ret = run_groq_model(messages, \"llama3-8b-8192\", max_tokens=16, temperature=0.0)\n",
        "    results.append(ret)"
      ],
      "metadata": {
        "id": "esZGMV_eje7q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results[:10]"
      ],
      "metadata": {
        "id": "q-cOlNc2oy0P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Post process the outputs in required format"
      ],
      "metadata": {
        "id": "KRap_98dntEy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def post(text):\n",
        "    return text.replace('[answer]', '').strip()"
      ],
      "metadata": {
        "id": "uY7hX5vYmzcW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds = [post(x) for x in results]\n",
        "golds = [x['numerical_answer'].strip() for x in test_dataset]\n",
        "print(Counter(preds))\n",
        "print('Accuracy', compute_accuracy(golds, preds))"
      ],
      "metadata": {
        "id": "edg0PsTAm_PA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Advanced Prompting Techniques - CoT, Self-consistency and PAL\n",
        "\n",
        "#### The model performance is not so great.\n",
        "\n",
        "#### But, wait!\n",
        "\n",
        "#### **As** humans we solve problems via step-wise reasoning. Let's add these reasoning steps (Chain-of-Thoughts) to the prompt and let model reason first and then answer."
      ],
      "metadata": {
        "id": "m3aJtm9WMEIw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def few_shot_prompt_with_COT(test_entry, exemplars):\n",
        "    messages = [{\"role\": \"system\", \"content\": \"MATH PROBLEM INSTRUCTIONS\"}]\n",
        "    for entry in exemplars:\n",
        "        messages.append({\"role\": \"user\", \"content\": \"QUESTION HERE\"})\n",
        "        messages.append({\"role\": \"assistant\", \"content\": \"ANSWER HERE\"})\n",
        "    messages.append({\"role\": \"user\", \"content\": \"QUESTION HERE\"})\n",
        "\n",
        "    return messages"
      ],
      "metadata": {
        "id": "dl5uV01SoQkX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = []\n",
        "for entry in tqdm(test_dataset):\n",
        "    messages = few_shot_prompt_with_COT(entry, exemplars)\n",
        "    ret = run_groq_model(messages, \"llama3-8b-8192\", max_tokens=200, temperature=0.0)\n",
        "    results.append(ret)"
      ],
      "metadata": {
        "id": "gtCZdHf7Mh0_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results[:10]"
      ],
      "metadata": {
        "id": "taGVBlPDMl9g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def post(text):\n",
        "    return text.split('\\n')[-1].split(' ', 1)[-1].strip()"
      ],
      "metadata": {
        "id": "b2xWim6YNEm5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds = [post(x) for x in results]\n",
        "golds = [x['numerical_answer'].strip() for x in test_dataset]\n",
        "print(Counter(preds))\n",
        "print('Accuracy', compute_accuracy(golds, preds))"
      ],
      "metadata": {
        "id": "ItjKlIoJNR1i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### A whooping 64% increase in performance. Let's try with Mixtral model."
      ],
      "metadata": {
        "id": "38VtLk0yNaaF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results = []\n",
        "for entry in tqdm(test_dataset):\n",
        "    messages = few_shot_prompt_with_COT(entry, exemplars)\n",
        "    ret = run_groq_model(messages, \"mixtral-8x7b-32768\", max_tokens=400, temperature=0.0)\n",
        "    results.append(ret)"
      ],
      "metadata": {
        "id": "HosMF9TiNTRu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results[:10]"
      ],
      "metadata": {
        "id": "dZ0cT4p6Nsjt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def post(text):\n",
        "    return text.split('\\n')[-1].split(' ', 1)[-1].strip()"
      ],
      "metadata": {
        "id": "3CGNp0hhPrC2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds = [post(x) for x in results]\n",
        "golds = [x['numerical_answer'] for x in test_dataset]\n",
        "print(Counter(preds))\n",
        "print('Accuracy', compute_accuracy(golds, preds))"
      ],
      "metadata": {
        "id": "z7BXlJZrPyxh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Self-consistency Chain-of-Thought Prompting\n",
        "\n",
        "Standard CoT prompts might get stuck on a single, potentially incorrect, reasoning path. In many cases, the answer could be reached through multiple approaches."
      ],
      "metadata": {
        "id": "HYwEiRdkWqlS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"A candle melts by 2 centimeters every hour that it burns. How many centimeters shorter will a candle be after burning from 1:00 PM to 5:00 PM?\"\n",
        "\n",
        "messages = few_shot_prompt_with_COT({'question': question}, exemplars)\n",
        "print('\\n\\n'.join([x['content'] for x in messages]))"
      ],
      "metadata": {
        "id": "dcWLCeJLP1kY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ret = run_groq_model(messages, \"llama3-8b-8192\", max_tokens=200, temperature=0.0)\n",
        "print(ret)"
      ],
      "metadata": {
        "id": "nHmfg_vRYBP2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ret = run_groq_model(messages, \"llama3-8b-8192\", max_tokens=200, temperature=0.9)\n",
        "print(ret)"
      ],
      "metadata": {
        "id": "J-J-kJkgaK8I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ret = run_groq_model(messages, \"llama3-8b-8192\", max_tokens=200, temperature=0.9)\n",
        "print(ret)"
      ],
      "metadata": {
        "id": "XldFHQS7aLYe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ret = run_groq_model(messages, \"llama3-8b-8192\", max_tokens=200, temperature=0.9)\n",
        "print(ret)"
      ],
      "metadata": {
        "id": "Sm-ebT2GaLz7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ret = run_groq_model(messages, \"llama3-8b-8192\", max_tokens=200, temperature=0.9)\n",
        "print(ret)"
      ],
      "metadata": {
        "id": "11PaeMVAaTPu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ret = run_groq_model(messages, \"llama3-8b-8192\", max_tokens=200, temperature=0.9)\n",
        "print(ret)"
      ],
      "metadata": {
        "id": "LE4nIfTeaUUB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Take Majority Voting across reasoning paths."
      ],
      "metadata": {
        "id": "39DTVSrzcEnX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "preds = []\n",
        "for entry in tqdm(test_dataset):\n",
        "    tmp = []\n",
        "    for jj in range(5):\n",
        "        messages = few_shot_prompt_with_COT(entry, exemplars)\n",
        "        ret = run_groq_model(messages, \"llama3-8b-8192\", max_tokens=200, temperature=0.7)\n",
        "        tmp.append(ret)\n",
        "    tmp = [post(x) for x in tmp]\n",
        "    majority = Counter(tmp).most_common(1)[0][0]\n",
        "    preds.append(majority)"
      ],
      "metadata": {
        "id": "b-gThPMrYHRK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tmp, majority, preds[-1]"
      ],
      "metadata": {
        "id": "l1d7fH6FhJ1O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "golds = [x['numerical_answer'] for x in test_dataset]\n",
        "# print(Counter(preds))\n",
        "print('Accuracy', compute_accuracy(golds, preds))"
      ],
      "metadata": {
        "id": "nlfblZysexkz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### LLMs and Mathematical Computations\n",
        "\n",
        "**Strength**\n",
        "\n",
        "LLMs are awesome for understanding a given problem and generating logical steps to solve the problems.\n",
        "\n",
        "**Weakness**\n",
        "\n",
        "Some logical steps require arithmatic computations.\n",
        "\n",
        "**Idea**\n",
        "\n",
        "Use calculators to run arithmatic computations.\n",
        "\n",
        "Specially, ask LLMs to output reasoning steps as Python code. Execute the code to obtain final results."
      ],
      "metadata": {
        "id": "1Q6Oc_bFsIlY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "codes = [\"\"\"Here is the step-by-step Python code for the given problem.\n",
        "```# Clips sold in April\n",
        "clips_april = 48\n",
        "\n",
        "# Clips sold in May (half of April)\n",
        "clips_may = clips_april / 2\n",
        "\n",
        "# Total clips sold\n",
        "total_clips = clips_april + clips_may\n",
        "print(\"FINAL ANSWER:\", total_clips)\n",
        "```\n",
        "The final answer is \"total_clip\" \"\"\",\n",
        "\n",
        "\"\"\"Here is the step-by-step Python code for the given problem.\n",
        "```\n",
        "# Hourly rate\n",
        "rate_per_hour = 12\n",
        "\n",
        "# Minutes worked\n",
        "minutes_worked = 50\n",
        "\n",
        "# Earnings per minute\n",
        "rate_per_minute = rate_per_hour / 60\n",
        "\n",
        "# Total earnings\n",
        "total_earnings = rate_per_minute * minutes_worked\n",
        "print(\"FINAL ANSWER:\", total_earnings)\n",
        "```\n",
        "The final answer is \"total_earnings\" \"\"\",\n",
        "\n",
        "\"\"\"Here is the step-by-step Python code for the given problem.\n",
        "```\n",
        "# Cost of the wallet\n",
        "wallet_cost = 100\n",
        "\n",
        "# Initial savings (half of the cost)\n",
        "initial_savings = wallet_cost / 2\n",
        "\n",
        "# Money given by parents\n",
        "parents_contribution = 15\n",
        "\n",
        "# Money given by grandparents (twice as much as parents)\n",
        "grandparents_contribution = parents_contribution * 2\n",
        "\n",
        "# Total savings after contributions\n",
        "total_savings = initial_savings + parents_contribution + grandparents_contribution\n",
        "\n",
        "# Money still needed\n",
        "money_needed = wallet_cost - total_savings\n",
        "print(\"FINAL ANSWER:\", money_needed)\n",
        "```\n",
        "The final answer is \"money_needed\" \"\"\",\n",
        "\n",
        "\"\"\"Here is the step-by-step Python code for the given problem.\n",
        "```\n",
        "# Total pages in the book\n",
        "total_pages = 120\n",
        "\n",
        "# Pages read yesterday\n",
        "pages_yesterday = 12\n",
        "\n",
        "# Pages read today (twice as many as yesterday)\n",
        "pages_today = pages_yesterday * 2\n",
        "\n",
        "# Total pages read so far\n",
        "total_pages_read = pages_yesterday + pages_today\n",
        "\n",
        "# Pages remaining\n",
        "pages_remaining = total_pages - total_pages_read\n",
        "\n",
        "# Pages to read tomorrow (half of the remaining pages)\n",
        "pages_tomorrow = pages_remaining / 2\n",
        "print(\"FINAL ANSWER:\", pages_tomorrow)\n",
        "```\n",
        "The final answer is \"pages_tomorrow\" \"\"\",\n",
        "\n",
        "\"\"\"Here is the step-by-step Python code for the given problem.\n",
        "```\n",
        "# Pages per letter\n",
        "pages_per_letter = 3\n",
        "\n",
        "# Friends\n",
        "num_friends = 2\n",
        "\n",
        "# Letters per week\n",
        "letters_per_week = 2\n",
        "\n",
        "# Pages written per week\n",
        "pages_per_week = pages_per_letter * num_friends * letters_per_week\n",
        "\n",
        "# Weeks in a year\n",
        "weeks_in_year = 52\n",
        "\n",
        "# Total pages written in a year\n",
        "total_pages_year = pages_per_week * weeks_in_year\n",
        "print(\"FINAL ANSWER:\", total_pages_year)\n",
        "```\n",
        "The final answer is \"total_pages_year\" \"\"\"\n",
        "]"
      ],
      "metadata": {
        "id": "uUE_6J19ZFDv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for jj, ee in enumerate(exemplars):\n",
        "    ee['code'] = codes[jj]"
      ],
      "metadata": {
        "id": "Yja0Rli_fWZx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def few_shot_prompt_with_code(test_entry, exemplars):\n",
        "    messages = [{\"role\": \"system\", \"content\": \"MATH PROBLEM INSTRUCTIONS\"}]\n",
        "    for entry in exemplars:\n",
        "        messages.append({\"role\": \"user\", \"content\": \"QUESTION HERE\"})\n",
        "        messages.append({\"role\": \"assistant\", \"content\": \"ANSWER HERE\"})\n",
        "    messages.append({\"role\": \"user\", \"content\": \"QUESTION HERE\"})\n",
        "\n",
        "    return messages"
      ],
      "metadata": {
        "id": "cpo6ius1h9_i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"A candle melts by 2 centimeters every hour that it burns. How many centimeters shorter will a candle be after burning from 1:00 PM to 5:00 PM?\"\n",
        "\n",
        "messages = few_shot_prompt_with_code({'question': question}, exemplars)\n",
        "print('\\n\\n'.join([x['content'] for x in messages]))"
      ],
      "metadata": {
        "id": "EQ1RtqKUiK9a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ret = run_groq_model(messages, \"llama3-8b-8192\", max_tokens=200, temperature=0.0)\n",
        "print(ret)"
      ],
      "metadata": {
        "id": "PhbCMlZliRR3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import io\n",
        "import sys\n",
        "\n",
        "def run_python_string(text):\n",
        "    lines = text.split('\\n')\n",
        "    idxs = [ii for ii in range(len(lines)) if '```' in lines[ii]]\n",
        "    if len(idxs) != 2:\n",
        "        return 'Code Error.'\n",
        "\n",
        "    code_str = '\\n'.join(lines[idxs[0] + 1: idxs[1]])\n",
        "    # Use a local namespace to avoid variable conflicts\n",
        "    local_var = {}\n",
        "\n",
        "    output_buffer = io.StringIO()\n",
        "    old_stdout = sys.stdout\n",
        "    sys.stdout = output_buffer\n",
        "\n",
        "    exec(code_str, globals(), local_var)\n",
        "\n",
        "    # Restore the original stdout\n",
        "    sys.stdout = old_stdout\n",
        "\n",
        "    # Get the output from the buffer\n",
        "    output = output_buffer.getvalue()\n",
        "\n",
        "    for line in output.split('\\n'):\n",
        "        if 'FINAL ANSWER:' in line:\n",
        "            return line.replace('FINAL ANSWER:', '').strip()\n",
        "\n",
        "    return 'Code Error.'\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "0MzDImhiict0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run_python_string(ret)"
      ],
      "metadata": {
        "id": "GeoJeqdzjO_w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = []\n",
        "for entry in tqdm(test_dataset):\n",
        "    messages = few_shot_prompt_with_code(entry, exemplars)\n",
        "    ret = run_groq_model(messages, \"llama3-8b-8192\", max_tokens=400, temperature=0.0)\n",
        "    results.append(ret)"
      ],
      "metadata": {
        "id": "auLzaNaFladu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for ii in range(5):\n",
        "    print(results[ii])\n",
        "    print('-' * 120)"
      ],
      "metadata": {
        "id": "HjJXDW5qjlb4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from copy import deepcopy\n",
        "\n",
        "preds = []\n",
        "\n",
        "orig_stdout = sys.stdout\n",
        "for ret in results:\n",
        "    try:\n",
        "        val = run_python_string(ret)\n",
        "    except:\n",
        "        val = 'Code Error.'\n",
        "    preds.append(val)\n",
        "sys.stdout = orig_stdout"
      ],
      "metadata": {
        "id": "7OseGVaQl7FL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds[:10]"
      ],
      "metadata": {
        "id": "mQYgpDR_p-9G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "golds = [x['numerical_answer'] for x in test_dataset]\n",
        "print(Counter(preds))\n",
        "print('Accuracy', compute_accuracy(golds, preds))"
      ],
      "metadata": {
        "id": "P0n8RVYvmOun"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tree of Thoughts\n",
        "\n",
        "\n",
        "Hulbert, Dave. \"Using Tree-of-Thought Prompting to Boost ChatGPT's Reasoning.\" Last modified May 2023. GitHub repository. Zenodo. https://doi.org/10.5281/zenodo.10323452. https://github.com/dave1010/tree-of-thought-prompting.\n",
        "\n",
        "We will use a modified version of ToT to solve a word problem.\n"
      ],
      "metadata": {
        "id": "3PkmzefPMFYh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"Tom has twice as many apples as Jerry. Together, they have 18 apples. How many apples does Tom have?\""
      ],
      "metadata": {
        "id": "CR4hTfDEMITn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"\"\"Imagine three different experts are answering this question. All experts will write down 1 step of their thinking, then share it with the group. Then all experts will go on to the next step, etc. If any expert realises they're wrong at any point then they leave. The question is...\n",
        "\n",
        "Simulate three brilliant, logical experts collaboratively answering a question. Each one verbosely explains their thought process in real-time, considering the prior explanations of others and openly acknowledging mistakes. At each step, whenever possible, each expert refines and builds upon the thoughts of others, acknowledging their contributions. They continue until there is a definitive answer to the question. For clarity, your entire response should be in a markdown table. The question is...\n",
        "\n",
        "Identify and behave as three different experts that are appropriate to answering this question.\n",
        "All experts will write down the step and their thinking about the step, then share it with the group.\n",
        "Then, all experts will go on to the next step, etc.\n",
        "At each step all experts will score their peers response between 1 and 5, 1 meaning it is highly unlikely, and 5 meaning it is highly likely.\n",
        "If any expert is judged to be wrong at any point then they leave.\n",
        "After all experts have provided their analysis, you then analyze all 3 analyses and provide either the consensus solution or your best guess solution.\n",
        "The question is...\n",
        "\n",
        "Question: \"\"\" + question\n",
        "\n",
        "print(prompt)"
      ],
      "metadata": {
        "id": "ZJOxZVbEp8O7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ret = run_groq_model([{'role': 'user', 'content': prompt}], \"llama3-8b-8192\", max_tokens=2048, temperature=0.0)\n",
        "print(ret)"
      ],
      "metadata": {
        "id": "vnDdH1KgMLWq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-ArJgcbLMLr1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}